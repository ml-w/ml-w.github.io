@inproceedings{RN565,
   author = {Clough, James R and Oksuz, Ilkay and Puyol-Antón, Esther and Ruijsink, Bram and King, Andrew P and Schnabel, Julia A},
   title = {Global and local interpretability for cardiac MRI classification},
   booktitle = {International Conference on Medical Image Computing and Computer-Assisted Intervention},
   publisher = {Springer},
   pages = {656-664},
   type = {Conference Proceedings}
}

@article{RN443,
   author = {Gulum, M. A. and Trombley, C. M. and Kantardzic, M.},
   title = {A Review of Explainable Deep Learning Cancer Detection Models in Medical Imaging},
   journal = {Applied Sciences-Basel},
   volume = {11},
   number = {10},
   pages = {4573},
   note = {St5qz
Times Cited:6
Cited References Count:142},
   abstract = {Deep learning has demonstrated remarkable accuracy analyzing images for cancer detection tasks in recent years. The accuracy that has been achieved rivals radiologists and is suitable for implementation as a clinical tool. However, a significant problem is that these models are black-box algorithms therefore they are intrinsically unexplainable. This creates a barrier for clinical implementation due to lack of trust and transparency that is a characteristic of black box algorithms. Additionally, recent regulations prevent the implementation of unexplainable models in clinical settings which further demonstrates a need for explainability. To mitigate these concerns, there have been recent studies that attempt to overcome these issues by modifying deep learning architectures or providing after-the-fact explanations. A review of the deep learning explanation literature focused on cancer detection using MR images is presented here. The gap between what clinicians deem explainable and what current methods provide is discussed and future suggestions to close this gap are provided.},
   keywords = {deep learning
explanability
explainability
cancer detecton
mri
xai
convolutional neural-networks
computer-aided detection
prostate-cancer
classification
diagnosis},
   ISSN = {2076-3417},
   DOI = {ARTN 4573
10.3390/app11104573},
   url = {<Go to ISI>://WOS:000662499000001},
   year = {2021},
   type = {Journal Article}
}

@misc{RN141,
   author = {Hassanin, Mohammed and Anwar, Saeed and Radwan, Ibrahim and Khan, Fahad S and Mian, Ajmal},
   title = {Visual Attention Methods in Deep Learning: An In-Depth Survey},
   year = {2022},
   type = {Electronic Article}
}

@misc{RN148,
   author = {Hong Kong Cancer Registry},
   title = {Cancer Facts: Nasopharyngeal Cancer in 2019},
   publisher = {Hospital Authoriy, Hong Kong},
   volume = {2022},
   number = {2nd Aug 2022},
   url = {https://www3.ha.org.hk/cancereg/pdf/factsheet/2019/npc_2019.pdf},
   year = {2019},
   type = {Web Page}
}

@article{RN295,
   author = {Ke, L. and Deng, Y. and Xia, W. and Qiang, M. and Chen, X. and Liu, K. and Jing, B. and He, C. and Xie, C. and Guo, X. and Lv, X. and Li, C.},
   title = {Development of a self-constrained 3D DenseNet model in automatic detection and segmentation of nasopharyngeal carcinoma using magnetic resonance images},
   journal = {Oral Oncol},
   volume = {110},
   pages = {104862},
   note = {Ke, Liangru
Deng, Yishu
Xia, Weixiong
Qiang, Mengyun
Chen, Xi
Liu, Kuiyuan
Jing, Bingzhong
He, Caisheng
Xie, Chuanmiao
Guo, Xiang
Lv, Xing
Li, Chaofeng
eng
Research Support, Non-U.S. Gov't
England
2020/07/03
Oral Oncol. 2020 Nov;110:104862. doi: 10.1016/j.oraloncology.2020.104862. Epub 2020 Jun 29.},
   abstract = {OBJECTIVES: We aimed to develop a dual-task model to detect and segment nasopharyngeal carcinoma (NPC) automatically in magnetic resource images (MRI) based on deep learning method, since the differential diagnosis of NPC and atypical benign hyperplasia was difficult and the radiotherapy target contouring of NPC was labor-intensive. MATERIALS AND METHODS: A self-constrained 3D DenseNet (SC-DenseNet) architecture was improved using separated training and validation sets. A total of 4100 individuals were finally enrolled and split into the training, validation and test sets at a proximate ratio of 8:1:1 using simple randomization. The diagnostic metrics of the established model against experienced radiologists was compared in the test set. The dice similarity coefficient (DSC) of manual and model-defined tumor region was used to evaluate the efficacy of segmentation. RESULTS: Totally, 3142 nasopharyngeal carcinoma (NPC) and 958 benign hyperplasia were included. The SC-DenseNet model showed encouraging performance in detecting NPC, attained a higher overall accuracy, sensitivity and specificity than those of the experienced radiologists (97.77% vs 95.87%, 99.68% vs 99.24% and 91.67% vs 85.21%, respectively). Moreover, the model also exhibited promising performance in automatic segmentation of tumor region in NPC, with an average DSC at 0.77 +/- 0.07 in the test set. CONCLUSIONS: The SC-DenseNet model showed competence in automatic detection and segmentation of NPC in MRI, indicating the promising application value as an assistant tool in clinical practice, especially in screening project.},
   keywords = {Adolescent
Adult
Aged
Aged, 80 and over
Child
Humans
Magnetic Resonance Imaging/*methods
Middle Aged
Nasopharyngeal Carcinoma/*diagnosis/*diagnostic imaging/pathology
Retrospective Studies
Young Adult
*Automatic segmentation
*Deep learning
*Detection
*Magnetic resource images
*Nasopharyngeal carcinoma},
   ISSN = {1879-0593 (Electronic)
1368-8375 (Linking)},
   DOI = {10.1016/j.oraloncology.2020.104862},
   url = {https://www.ncbi.nlm.nih.gov/pubmed/32615440},
   year = {2020},
   type = {Journal Article}
}

@article{RN568,
   author = {Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
   title = {Large language models are zero-shot reasoners},
   journal = {Advances in neural information processing systems},
   volume = {35},
   pages = {22199-22213},
   year = {2022},
   type = {Journal Article}
}

@article{RN125,
   author = {Linardatos, P. and Papastefanopoulos, V. and Kotsiantis, S.},
   title = {Explainable AI: A Review of Machine Learning Interpretability Methods},
   journal = {Entropy (Basel)},
   volume = {23},
   number = {1},
   pages = {18},
   note = {Linardatos, Pantelis
Papastefanopoulos, Vasilis
Kotsiantis, Sotiris
eng
Review
Switzerland
2020/12/31
Entropy (Basel). 2020 Dec 25;23(1). pii: e23010018. doi: 10.3390/e23010018.},
   abstract = {Recent advances in artificial intelligence (AI) have led to its widespread industrial adoption, with machine learning systems demonstrating superhuman performance in a significant number of tasks. However, this surge in performance, has often been achieved through increased model complexity, turning such systems into "black box" approaches and causing uncertainty regarding the way they operate and, ultimately, the way that they come to decisions. This ambiguity has made it problematic for machine learning systems to be adopted in sensitive yet critical domains, where their value could be immense, such as healthcare. As a result, scientific interest in the field of Explainable Artificial Intelligence (XAI), a field that is concerned with the development of new methods that explain and interpret machine learning models, has been tremendously reignited over recent years. This study focuses on machine learning interpretability methods; more specifically, a literature review and taxonomy of these methods are presented, as well as links to their programming implementations, in the hope that this survey would serve as a reference point for both theorists and practitioners.},
   keywords = {black-box
explainability
fairness
interpretability
machine learning
sensitivity
xai},
   ISSN = {1099-4300 (Electronic)
1099-4300 (Linking)},
   DOI = {10.3390/e23010018},
   url = {https://www.ncbi.nlm.nih.gov/pubmed/33375658
https://mdpi-res.com/d_attachment/entropy/entropy-23-00018/article_deploy/entropy-23-00018-v2.pdf?version=1609160444},
   year = {2020},
   type = {Journal Article}
}

@article{RN561,
   author = {Liu, Xiaodong and He, Pengcheng and Chen, Weizhu and Gao, Jianfeng},
   title = {Multi-task deep neural networks for natural language understanding},
   journal = {arXiv preprint arXiv:1901.11504},
   year = {2019},
   type = {Journal Article}
}

@article{RN566,
   author = {Pang, Ting and Li, Peigao and Zhao, Lijie},
   title = {A survey on automatic generation of medical imaging reports based on deep learning},
   journal = {BioMedical Engineering OnLine},
   volume = {22},
   number = {1},
   pages = {1-16},
   ISSN = {1475-925X},
   year = {2023},
   type = {Journal Article}
}

@inproceedings{RN29,
   author = {Park, Chunjong and Awadalla, Anas and Kohno, Tadayoshi and Patel, Shwetak},
   title = {Reliable and Trustworthy Machine Learning for Health Using Dataset Shift Detection},
   booktitle = {Thirty-Fifth Conference on Neural Information Processing Systems},
   type = {Conference Proceedings}
}

@inproceedings{RN442,
   author = {Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
   title = {Grad-cam: Visual explanations from deep networks via gradient-based localization},
   booktitle = {Proceedings of the IEEE international conference on computer vision},
   pages = {618-626},
   type = {Conference Proceedings}
}

@inproceedings{RN563,
   author = {Standley, Trevor and Zamir, Amir and Chen, Dawn and Guibas, Leonidas and Malik, Jitendra and Savarese, Silvio},
   title = {Which tasks should be learned together in multi-task learning?},
   booktitle = {International Conference on Machine Learning},
   publisher = {PMLR},
   pages = {9120-9132},
   ISBN = {2640-3498},
   type = {Conference Proceedings}
}

@article{RN26,
   author = {Thiagarajan, Jayaraman J and Sattigeri, Prasanna and Rajan, Deepta and Venkatesh, Bindya},
   title = {Calibrating healthcare ai: Towards reliable and interpretable deep predictive models},
   journal = {arXiv preprint arXiv:2004.14480},
   year = {2020},
   type = {Journal Article}
}

@article{RN562,
   author = {van der Velden, B. H. M. and Kuijf, H. J. and Gilhuijs, K. G. A. and Viergever, M. A.},
   title = {Explainable artificial intelligence (XAI) in deep learning-based medical image analysis},
   journal = {Med Image Anal},
   volume = {79},
   pages = {102470},
   note = {van der Velden, Bas H M
Kuijf, Hugo J
Gilhuijs, Kenneth G A
Viergever, Max A
eng
Research Support, Non-U.S. Gov't
Review
Netherlands
2022/05/17
Med Image Anal. 2022 Jul;79:102470. doi: 10.1016/j.media.2022.102470. Epub 2022 May 4.},
   abstract = {With an increase in deep learning-based methods, the call for explainability of such methods grows, especially in high-stakes decision making areas such as medical image analysis. This survey presents an overview of explainable artificial intelligence (XAI) used in deep learning-based medical image analysis. A framework of XAI criteria is introduced to classify deep learning-based medical image analysis methods. Papers on XAI techniques in medical image analysis are then surveyed and categorized according to the framework and according to anatomical location. The paper concludes with an outlook of future opportunities for XAI in medical image analysis.},
   keywords = {*Artificial Intelligence
*Deep Learning
Humans
Deep learning
Explainable artificial intelligence
Interpretable deep learning
Medical image analysis
Survey},
   ISSN = {1361-8423 (Electronic)
1361-8415 (Linking)},
   DOI = {10.1016/j.media.2022.102470},
   url = {https://www.ncbi.nlm.nih.gov/pubmed/35576821
https://www.sciencedirect.com/science/article/pii/S1361841522001177?via%3Dihub},
   year = {2022},
   type = {Journal Article}
}

@article{RN567,
   author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny},
   title = {Chain-of-thought prompting elicits reasoning in large language models},
   journal = {Advances in Neural Information Processing Systems},
   volume = {35},
   pages = {24824-24837},
   year = {2022},
   type = {Journal Article}
}

@article{RN553,
   author = {Wong, L. M. and Ai, Q. Y. H. and Zhang, R. and Mo, F. and King, A. D.},
   title = {Radiomics for Discrimination between Early-Stage Nasopharyngeal Carcinoma and Benign Hyperplasia with Stable Feature Selection on MRI},
   journal = {Cancers (Basel)},
   volume = {14},
   number = {14},
   pages = {3433},
   note = {Wong, Lun M
Ai, Qi Yong H
Zhang, Rongli
Mo, Frankie
King, Ann D
eng
Switzerland
2022/07/28
Cancers (Basel). 2022 Jul 14;14(14):3433. doi: 10.3390/cancers14143433.},
   abstract = {Discriminating early-stage nasopharyngeal carcinoma (NPC) from benign hyperplasia (BH) on MRI is a challenging but important task for the early detection of NPC in screening programs. Radiomics models have the potential to meet this challenge, but instability in the feature selection step may reduce their reliability. Therefore, in this study, we aim to discriminate between early-stage T1 NPC and BH on MRI using radiomics and propose a method to improve the stability of the feature selection step in the radiomics pipeline. A radiomics model was trained using data from 442 patients (221 early-stage T1 NPC and 221 with BH) scanned at 3T and tested on 213 patients (99 early-stage T1 NPC and 114 BH) scanned at 1.5T. To verify the improvement in feature selection stability, we compared our proposed ensemble technique, which uses a combination of bagging and boosting (BB-RENT), with the well-established elastic net. The proposed radiomics model achieved an area under the curve of 0.85 (95% confidence interval (CI): 0.82-0.89) and 0.80 (95% CI: 0.74-0.86) in discriminating NPC and BH in the 3T training and 1.5T testing cohort, respectively, using 17 features selected from a pool of 422 features by the proposed feature selection technique. BB-RENT showed a better feature selection stability compared to the elastic net (Jaccard index = 0.39 +/- 0.14 and 0.24 +/- 0.06, respectively; p < 0.001).},
   keywords = {benign hyperplasia
feature selection stability
machine learning
magnetic resonance imaging
nasopharyngeal carcinoma
radiomics},
   ISSN = {2072-6694 (Print)
2072-6694 (Electronic)
2072-6694 (Linking)},
   DOI = {10.3390/cancers14143433},
   url = {https://www.ncbi.nlm.nih.gov/pubmed/35884494
https://mdpi-res.com/d_attachment/cancers/cancers-14-03433/article_deploy/cancers-14-03433-v2.pdf?version=1657866800},
   year = {2022},
   type = {Journal Article}
}

@article{RN437,
   author = {Wong, L. M. and King, A. D. and Ai, Q. Y. H. and Lam, W. K. J. and Poon, D. M. C. and Ma, B. B. Y. and Chan, K. C. A. and Mo, F. K. F.},
   title = {Convolutional neural network for discriminating nasopharyngeal carcinoma and benign hyperplasia on MRI},
   journal = {Eur Radiol},
   volume = {31},
   number = {6},
   pages = {3856-3863},
   note = {Wong, Lun M
King, Ann D
Ai, Qi Yong H
Lam, W K Jacky
Poon, Darren M C
Ma, Brigette B Y
Chan, K C Allen
Mo, Frankie K F
eng
Germany
2020/11/27
Eur Radiol. 2021 Jun;31(6):3856-3863. doi: 10.1007/s00330-020-07451-y. Epub 2020 Nov 25.},
   abstract = {OBJECTIVES: A convolutional neural network (CNN) was adapted to automatically detect early-stage nasopharyngeal carcinoma (NPC) and discriminate it from benign hyperplasia on a non-contrast-enhanced MRI sequence for potential use in NPC screening programs. METHODS: We retrospectively analyzed 412 patients who underwent T2-weighted MRI, 203 of whom had biopsy-proven primary NPC confined to the nasopharynx (stage T1) and 209 had benign hyperplasia without NPC. Thirteen patients were sampled randomly to monitor the training process. We applied the Residual Attention Network architecture, adapted for three-dimensional MR images, and incorporated a slice-attention mechanism, to produce a CNN score of 0-1 for NPC probability. Threefold cross-validation was performed in 399 patients. CNN scores between the NPC and benign hyperplasia groups were compared using Student's t test. Receiver operating characteristic with the area under the curve (AUC) was performed to identify the optimal CNN score threshold. RESULTS: In each fold, significant differences were observed in the CNN scores between the NPC and benign hyperplasia groups (p < .01). The AUCs ranged from 0.95 to 0.97 with no significant differences between the folds (p = .35 to .92). The combined AUC from all three folds (n = 399) was 0.96, with an optimal CNN score threshold of > 0.71, producing a sensitivity, specificity, and accuracy of 92.4%, 90.6%, and 91.5%, respectively, for NPC detection. CONCLUSION: Our CNN method applied to T2-weighted MRI could discriminate between malignant and benign tissues in the nasopharynx, suggesting that it as a promising approach for the automated detection of early-stage NPC. KEY POINTS: * The convolutional neural network (CNN)-based algorithm could automatically discriminate between malignant and benign diseases using T2-weighted fat-suppressed MR images. * The CNN-based algorithm had an accuracy of 91.5% with an area under the receiver operator characteristic curve of 0.96 for discriminating early-stage T1 nasopharyngeal carcinoma from benign hyperplasia. * The CNN-based algorithm had a sensitivity of 92.4% and specificity of 90.6% for detecting early-stage nasopharyngeal carcinoma.},
   keywords = {Humans
Hyperplasia/diagnostic imaging
*Magnetic Resonance Imaging
Nasopharyngeal Carcinoma/diagnostic imaging
*Nasopharyngeal Neoplasms/diagnostic imaging
Neural Networks, Computer
Retrospective Studies
Computational neural network
Deep learning
Early detection of cancer
Hyperplasia
Nasopharyngeal carcinoma},
   ISSN = {1432-1084 (Electronic)
0938-7994 (Linking)},
   DOI = {10.1007/s00330-020-07451-y},
   url = {https://www.ncbi.nlm.nih.gov/pubmed/33241522
https://link.springer.com/content/pdf/10.1007/s00330-020-07451-y.pdf},
   year = {2021},
   type = {Journal Article}
}

@article{RN569,
   author = {Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Xu, Tong and Wang, Hao and Sui, Dianbo and Shen, Yunhang and Li, Ke and Sun, Xing and Chen, Enhong},
   title = {Woodpecker: Hallucination correction for multimodal large language models},
   journal = {arXiv preprint arXiv:2310.16045},
   year = {2023},
   type = {Journal Article}
}


@article{yin2023,
	title = {Woodpecker: Hallucination Correction for Multimodal Large Language Models},
	author = {Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Xu, Tong and Wang, Hao and Sui, Dianbo and Shen, Yunhang and Li, Ke and Sun, Xing and Chen, Enhong},
	year = {2023},
	date = {2023},
	doi = {10.48550/ARXIV.2310.16045},
	url = {https://arxiv.org/abs/2310.16045}
}


@article{guerreiro2023,
	title = {Hallucinations in Large Multilingual Translation Models},
	author = {Guerreiro, Nuno M. and Alves, Duarte and Waldendorf, Jonas and Haddow, Barry and Birch, Alexandra and Colombo, Pierre and Martins, {André F. T.}},
	year = {2023},
	date = {2023},
	doi = {10.48550/ARXIV.2303.16104},
	url = {https://arxiv.org/abs/2303.16104}
}
