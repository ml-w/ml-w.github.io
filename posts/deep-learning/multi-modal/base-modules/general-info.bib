
@article{vaswani2017,
	title = {Attention Is All You Need},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	year = {2017},
	date = {2017},
	doi = {10.48550/ARXIV.1706.03762},
	url = {https://arxiv.org/abs/1706.03762}
}

@article{devlin2018,
	title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	year = {2018},
	date = {2018},
	doi = {10.48550/ARXIV.1810.04805},
	url = {https://arxiv.org/abs/1810.04805}
}

@article{radford2018,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}

@article{radford2019,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{radford2021,
	title = {Learning Transferable Visual Models From Natural Language Supervision},
	author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
	year = {2021},
	date = {2021},
	doi = {10.48550/ARXIV.2103.00020},
	url = {https://arxiv.org/abs/2103.00020}
}

@article{zhang2020,
	title = {Contrastive Learning of Medical Visual Representations from Paired Images and Text},
	author = {Zhang, Yuhao and Jiang, Hang and Miura, Yasuhide and Manning, Christopher D. and Langlotz, Curtis P.},
	year = {2020},
	date = {2020},
	doi = {10.48550/ARXIV.2010.00747},
	url = {https://arxiv.org/abs/2010.00747}
}

@article{li2022,
	title = {BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation},
	author = {Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
	year = {2022},
	date = {2022},
	doi = {10.48550/ARXIV.2201.12086},
	url = {https://arxiv.org/abs/2201.12086}
}

@article{li2023,
	title = {BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models},
	author = {Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
	year = {2023},
	date = {2023},
	doi = {10.48550/ARXIV.2301.12597},
	url = {https://arxiv.org/abs/2301.12597}
}

@article{li2021,
	title = {SelfDoc: Self-Supervised Document Representation Learning},
	author = {Li, Peizhao and Gu, Jiuxiang and Kuen, Jason and Morariu, Vlad I. and Zhao, Handong and Jain, Rajiv and Manjunatha, Varun and Liu, Hongfu},
	year = {2021},
	date = {2021},
	doi = {10.48550/ARXIV.2106.03331},
	url = {https://arxiv.org/abs/2106.03331}
}
