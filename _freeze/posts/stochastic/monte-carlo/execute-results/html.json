{
  "hash": "bd6a3b787d9c4f1264de8608b18e41f2",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Stochastic - Particle Filtering and Markov Chain Monte Carlo\"\nauthor: \"MLun Wong\"\ndate: \"2017-05-11\"\ncategories: [stochastic, python, random, notes, monte carlo, mcmc]\n---\n\n::: callout-caution\nUnder construction\n:::\n\n# Definition\n\n## Particle\n\n> A particle can be seen as an evaluation of all random variables in a joint distribution.\n\nExamples:\n\n$$\\displaystyle  \\text{Particle A: } [X=1, Y=2] \\\\ \\\\ \\text{Particle B: } [X=3, Y=1] \\\\ \\\\ \\text{where } X, Y \\in  {1, 2, 3}$$\n\n## MCMC\n\n> MCMC refers to methods for randomly sample particles from a joint distribution with a Markov Chain.\n\n## Particle Filtering\n\n> Particle Filtering is also termed Sequential Monte Carlo. It refers to the process of repeatedly sampling, cast votes after each iteration based on sampled particles and modify the next sampling based on the votes in order to obtain the probability distribution of some un-observable states.\n\nFormally, let $x$ be the unobservable states and $y$ be the observable states related to $x$. Suppose we receive observations of $y$ at each time step $k$, we can write the probability based on a Markov Chain:\n\n$$\\displaystyle X_k\\|(X\\_{k-1} =x\\_{k-1}) \\propto p(x_k\\|x\\_{k-1})$$\n\n$$\\displaystyle Y_k\\|(X\\_{k} =x\\_{k}) \\propto p(y_k\\|x\\_{k})$$\n\nBased on Chapman-Kolmogorov Equation and Bayes Theorem, the conditional probability distribution of latent states $x$ based on priori knowledge $y$ is:\n\n$$\\displaystyle p(x_k\\|y\\_{1:k}) \\propto p(y_k\\|x_k)\\int_k p(x_k\\|x\\_{k-1})p(x\\_{k-1}\\|Y\\_{1:K-1})$$\n\n# MCMC Methods\n\n## Gibbs Sampling\n\n::: psuedo-code\n\n```{pseudocode}\n#| label: alg-quicksort\n#| html-indent-size: \"1.2em\"\n#| html-comment-delimiter: \"//\"\n#| html-line-number: true\n#| html-line-number-punc: \":\"\n#| html-no-end: false\n#| pdf-placement: \"htb!\"\n#| pdf-line-number: true\n\n\\begin{algorithm}\n\\caption{Quicksort}\n\\begin{algorithmic}\n\\Procedure{Quicksort}{$A, p, r$}\n  \\If{$p < r$}\n    \\State $q = $ \\Call{Partition}{$A, p, r$}\n    \\State \\Call{Quicksort}{$A, p, q - 1$}\n    \\State \\Call{Quicksort}{$A, q + 1, r$}\n  \\EndIf\n\\EndProcedure\n\\Procedure{Partition}{$A, p, r$}\n  \\State $x = A[r]$\n  \\State $i = p - 1$\n  \\For{$j = p, \\dots, r - 1$}\n    \\If{$A[j] < x$}\n      \\State $i = i + 1$\n      \\State exchange\n      $A[i]$ with     $A[j]$\n    \\EndIf\n    \\State exchange $A[i]$ with $A[r]$\n  \\EndFor\n\\EndProcedure\n\\end{algorithmic}\n\\end{algorithm}\n```\n\n\n**Unknown:** Joint distribution \\$P(X_1, X_2, \\dots, X_n) \\$\n\n**Known:** Conditional Probability \\$P(X_i\\|\\vec{X}\\_{others}) \\$\n\n**Goal:** Obtain an estimation of the joint distribution\n\nSteps:\n\n1.  Choose an initial value  $X\\^0_i$ for the variable of interest.\n\n2.  Compute distribution by randomly fixing  \"others\" variable \\$P(X_j\\|X_i, \\vec{X}\\_{others}) \\$ for some $j \\neq i$\n\n3.  Sample from distribution to get a realization of \\$X_j \\$, then update the conditional probability \\$P(X_i\\|X_j, \\vec{X}\\_{others}) \\$ correspondingly,\n\n4.  Sample the target\n\n5.  Do step 2 to step 3 repeatedly for all \\$j \\in [1, n] \\neq i \\$ for *k* iterations.\n:::\n\nAn implementation is given below:\n\n::: {#aaec5d37 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.integrate as integrate \nimport seaborn as sns \nimport tqdm.auto as auto  \n\n\"\"\" \nThis program demonstrates a two-variable Gibbs sampling iteration.  \nSuppose we are now interested in knowing P(X, Y), and both P(X|Y)  \nand P(Y|X) is known.  \n\nVariables: \n   PX, PY: \n        Pre-defined probability distribution of the two random variable. \n   properties: \n        Property of the pdf PX and PY, including the domain, resolution and a norm constant which is for plotting p.m.f  \n\"\"\" \n\ndef GenerateSamplers(): \n    \"\"\" \n    Creates a pair of random variables, one probability distribution is a \n    gaussian mixture, another is a simple gaussian with mean 0 and sd 10.  \n    Domain of the sample is set to -10 to 10  \n    :return [lambda: sample1, lambda: sample2: \n    \"\"\" \n    # Properties settings \n    resolution = 500 # 2000 partitions between whole domain \n    domain = [-10, 10] \n    gm = {'means': [-1, 2, -4], 'sds': [0.4, 8, 3], 'weight': [0.1, 0.6, 0.3]} \n    gy = {'means': 0, 'sds': 2}  \n    # define a normed gaussian \n    def Gaussian(mean, var, x): \n        return 1 / (var * np.sqrt(2 * np.pi)) * np.exp(-0.5 * (x - mean) ** 2 / var ** 2)  \n    \n    w = np.linspace(domain[0], domain[1], resolution)  \n    \n    # Generate pdf w/o normalization \n    _PX = lambda x: np.sum([gm['weight'][i]*Gaussian(gm['means'][i], gm['sds'][i], x) for i in range(len(gm['means']))], axis=0)  \n        _PY = lambda x: Gaussian(gy['means'], gy['sds'], x)  \n    \n    # Normalization \n    PX = lambda x: _PX(x) / integrate.quad(_PX, domain[0], domain[1])[0] # quad return mean, sd \n    PY = lambda x: _PY(x) / integrate.quad(_PY, domain[0], domain[1])[0]   \n    \n    # Create sampler functions \n    properties = {\n        'resolution': resolution, \n        'domain': domain, \n        'normConstant': (domain[1] - domain[0])/float(resolution - 1)\n    } \n    return PX, PY, properties\n\n'''main'''\nPX, PY, properties = GenerateSamplers() \nw = np.linspace(\n    properties['domain'][0], \n    properties['domain'][1], \n    properties['resolution']\n)  \n P_joint = lambda x: PX(x[0]) * PY(x[1]) \n PYcX = lambda x, y: P_joint((x, y)) / PX(x) # We somehow know this, here it is the arithmetic form, it could be established \n PXcY = lambda x, y: P_joint((x, y)) / PY(y) # with other methods (e.g., empirically estimated)      \n samples = [] \n x_k = float(np.random.choice(w)) # Initial sample \n for k in auto.trange(25000): \n\n  # Sample y_k based on X_k of the last iteration \n\n  _nPYcX = PYcX(x_k, w).sum() # normalize factor, for entertaining choice \n\n  y_k = np.random.choice(w, p=PYcX(x_k, w)/_nPYcX, size=1) # sample from new probability distribution \n\n   \n\n  # Now do it for x_k \n\n  _nPXcY = PXcY(w, y_k).sum() \n\n  x_k = np.random.choice(w, p=PXcY(w, y_k)/_nPXcY, size=1) \n\n  samples.append((float(x_k), float(y_k))) # Record the sample       \n # Plotting \n samples = np.stack(samples) \n joint_pdf = lambda x: PX(x[0]) * PY(x[1]) # This is what we are trying to estimate  \n joint_mesh = np.meshgrid(w, w) \n fig, ax = plt.subplots(1, 1, figsize=(6, 6)) \n CS = ax.contour(joint_mesh[0], joint_mesh[1], joint_pdf(joint_mesh), alpha=0.6, label=\"Estimated $P(X,Y)$\")      \n ax.scatter(samples[:, 0], samples[:, 1], s=2, alpha=0.2) \n ax.legend() \n plt.show() \n\n```\n:::\n\n\nThe result is the following figure, where the sampled points are in blue and the contour of the joint distribution $P(X, Y)$ is drawn:\n\n# Reference\n\n> http://cs.stanford.edu/\\~ppasupat/a9online/1300.html\n\n",
    "supporting": [
      "monte-carlo_files"
    ],
    "filters": [],
    "includes": {}
  }
}